#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºŽ Langchain çš„é—®ç­” Agent
ä¸“é—¨è´Ÿè´£æ ¹æ®æ£€ç´¢åˆ°çš„æ³•å¾‹æ¡æ–‡ç”Ÿæˆä¸“ä¸šå‡†ç¡®çš„æ³•å¾‹å›žç­”
"""
from typing import Dict, Any, List, Optional
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import PromptTemplate
from langchain_core.language_models.base import BaseLanguageModel
from langchain_core.output_parsers import StrOutputParser
from langchain.chains import LLMChain
from .llm_config import get_default_llm
from .tools import content_analysis_tool
from .memory_manager import get_memory_manager


class LawQAAgent:
    """æ³•å¾‹é—®ç­” Agent"""
    
    def __init__(self, 
                 llm: Optional[BaseLanguageModel] = None,
                 answer_style: str = "professional"):
        """
        åˆå§‹åŒ–é—®ç­” Agent
        
        Args:
            llm: è¯­è¨€æ¨¡åž‹å®žä¾‹
            answer_style: å›žç­”é£Žæ ¼ (professional/simple/detailed)
        """
        self.llm = llm or get_default_llm()
        self.answer_style = answer_style
        self.memory_manager = get_memory_manager()
        self.qa_chain = None
        self._initialized = False
        
        # å®šä¹‰ä¸åŒé£Žæ ¼çš„æç¤ºæ¨¡æ¿
        self.style_prompts = {
            "professional": self._get_professional_prompt(),
            "simple": self._get_simple_prompt(),
            "detailed": self._get_detailed_prompt()
        }
    
    def _get_professional_prompt(self) -> str:
        """ä¸“ä¸šé£Žæ ¼æç¤ºæ¨¡æ¿"""
        return """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ³•å¾‹é¡¾é—®ï¼Œå…·æœ‰æ·±åŽšçš„æ³•å­¦åŠŸåº•å’Œä¸°å¯Œçš„å®žåŠ¡ç»éªŒã€‚è¯·åŸºäºŽæä¾›çš„æ³•å¾‹æ¡æ–‡ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€è¿žè´¯çš„æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚

å¯¹è¯åŽ†å²ï¼š
{chat_history}

ç”¨æˆ·é—®é¢˜ï¼š
{question}

ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼š
{legal_context}

è¯·æä¾›ä¸“ä¸šçš„æ³•å¾‹å›žç­”ï¼Œè¦æ±‚ï¼š
- ä¸¥æ ¼åŸºäºŽæä¾›çš„æ³•å¾‹æ¡æ–‡è¿›è¡Œåˆ†æžï¼Œæ˜Žç¡®æŒ‡å‡ºé€‚ç”¨çš„å…·ä½“æ³•å¾‹æ¡æ¬¾
- å…¨é¢é˜è¿°ç›¸å…³çš„æ³•å¾‹è§„å®šå’Œå¯èƒ½çš„æ³•å¾‹åŽæžœ
- ç»“åˆå®žåŠ¡ç»éªŒæä¾›å®žç”¨çš„æ³•å¾‹å»ºè®®ï¼Œå¹¶æŒ‡å‡ºéœ€è¦æ³¨æ„çš„æ³•å¾‹é£Žé™©
- è¯­è¨€ä¸“ä¸šè§„èŒƒï¼Œé€»è¾‘æ¸…æ™°ï¼Œå›žç­”è¿žè´¯å®Œæ•´
- å¦‚æžœæ¡æ–‡ä¸è¶³ä»¥å®Œå…¨å›žç­”é—®é¢˜ï¼Œè¯·æ˜Žç¡®è¯´æ˜Ž
- å¯¹äºŽå¤æ‚æ¡ˆä»¶å»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆï¼Œé¿å…æä¾›å…·ä½“çš„è¯‰è®¼æŒ‡å¯¼

å›žç­”ï¼š"""

    def _get_simple_prompt(self) -> str:
        """ç®€å•é£Žæ ¼æç¤ºæ¨¡æ¿"""
        return """ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„æ³•å¾‹åŠ©æ‰‹ï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å›žç­”ç”¨æˆ·çš„æ³•å¾‹é—®é¢˜ã€‚

å¯¹è¯åŽ†å²ï¼š
{chat_history}

ç”¨æˆ·é—®é¢˜ï¼š
{question}

ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼š
{legal_context}

è¯·ç”¨ç®€å•æ˜Žäº†çš„è¯­è¨€å›žç­”ç”¨æˆ·çš„é—®é¢˜ï¼š
- å…ˆç”¨é€šä¿—çš„è¯è§£é‡Šç›¸å…³çš„æ³•å¾‹è§„å®šï¼Œé¿å…ä½¿ç”¨è¿‡å¤šä¸“ä¸šæœ¯è¯­
- è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œè´´è¿‘ç”Ÿæ´»ï¼Œé‡ç‚¹çªå‡º,å­—æ•°å°½é‡å°‘è€Œç²¾
- å¦‚æžœæƒ…å†µæ¯”è¾ƒå¤æ‚ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ

å›žç­”ï¼š"""

    def _get_detailed_prompt(self) -> str:
        """è¯¦ç»†é£Žæ ¼æç¤ºæ¨¡æ¿"""
        return """ä½ æ˜¯ä¸€ä½æ³•å­¦æ•™æŽˆå’Œå®žåŠ¡ä¸“å®¶ï¼Œè¯·æä¾›è¯¦ç»†ã€å…¨é¢çš„æ³•å¾‹åˆ†æžã€‚

å¯¹è¯åŽ†å²ï¼š
{chat_history}

ç”¨æˆ·é—®é¢˜ï¼š
{question}

ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼š
{legal_context}

è¯·æä¾›è¯¦ç»†å…¨é¢çš„æ³•å¾‹åˆ†æžï¼š
é¦–å…ˆæ·±å…¥åˆ†æžé—®é¢˜çš„æ³•å¾‹æ€§è´¨å’Œäº‰è®®ç„¦ç‚¹ï¼Œç„¶åŽé€æ¡è§£è¯»ç›¸å…³æ³•å¾‹æ¡æ–‡çš„å«ä¹‰å’Œé€‚ç”¨æ¡ä»¶ï¼Œé˜è¿°ç›¸å…³çš„æ³•ç†åŸºç¡€å’Œç«‹æ³•ç›®çš„ã€‚è¿›ä¸€æ­¥ç»“åˆå¸æ³•å®žè·µå’Œæ¡ˆä¾‹è¿›è¡Œåˆ†æžï¼Œå¦‚æžœå­˜åœ¨äº‰è®®ï¼Œåº”åˆ—ä¸¾ä¸åŒçš„æ³•å¾‹è§‚ç‚¹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šå…¨é¢è¯„ä¼°å„ç§å¯èƒ½çš„æ³•å¾‹é£Žé™©ï¼Œæœ€åŽæä¾›å…·ä½“çš„æ“ä½œæŒ‡å¯¼å’Œæ³¨æ„äº‹é¡¹ã€‚

è¦æ±‚åˆ†æžå…¨é¢æ·±å…¥ã€é€»è¾‘ä¸¥å¯†ï¼Œå¼•ç”¨å…·ä½“çš„æ³•å¾‹æ¡æ–‡å’Œç¼–å·ï¼Œè€ƒè™‘ä¸åŒæƒ…å†µå’Œä¾‹å¤–æƒ…å½¢ï¼Œæä¾›å¯æ“ä½œçš„å»ºè®®ã€‚å¯¹äºŽå¤æ‚æ¡ˆä»¶åº”å¼ºè°ƒéœ€è¦ä¸“ä¸šå¾‹å¸ˆçš„æŒ‡å¯¼ã€‚

å›žç­”ï¼š"""

    def initialize(self) -> bool:
        """åˆå§‹åŒ– Agent"""
        if self._initialized:
            return True
        
        try:
            # åˆ›å»ºé—®ç­”é“¾
            prompt_template = self.style_prompts.get(self.answer_style, self.style_prompts["professional"])
            prompt = PromptTemplate(
                input_variables=["question", "legal_context", "chat_history"],
                template=prompt_template
            )
            
            self.qa_chain = LLMChain(
                llm=self.llm,
                prompt=prompt,
                output_parser=StrOutputParser()
            )
            
            self._initialized = True
            print(f"âœ… é—®ç­” Agent åˆå§‹åŒ–æˆåŠŸ (é£Žæ ¼: {self.answer_style})")
            return True
            
        except Exception as e:
            print(f"âŒ é—®ç­” Agent åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def answer(self, 
                    question: str,
                    legal_context: str,
                    additional_context: Optional[str] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ³•å¾‹é—®ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            legal_context: æ³•å¾‹æ¡æ–‡ä¸Šä¸‹æ–‡
            additional_context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            é—®ç­”ç»“æžœ
        """
        if not self._initialized:
            if not self.initialize():
                return {"error": "Agent åˆå§‹åŒ–å¤±è´¥"}
        
        try:
            # èŽ·å–å¯¹è¯åŽ†å²
            formatted_history = self.memory_manager.format_chat_history_for_context()
            
            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context = legal_context
            if additional_context:
                context += f"\n\nè¡¥å……ä¿¡æ¯ï¼š\n{additional_context}"
            
            # æž„é€ è¾“å…¥
            chain_input = {
                "question": question,
                "legal_context": context,
                "chat_history": formatted_history
            }
            
            print(f"ðŸ’¬ ç”Ÿæˆå›žç­”: {question[:50]}...")
            
            # æ‰§è¡Œé—®ç­”é“¾
            answer = await self.qa_chain.ainvoke(chain_input)
            
            # å¤„ç†ç»“æžœ
            response = {
                "success": True,
                "question": question,
                "answer": answer["text"] if isinstance(answer, dict) else answer,
                "answer_style": self.answer_style,
                "context_used": bool(legal_context),
                "agent_type": "qa"
            }
            
            print("âœ… å›žç­”ç”Ÿæˆå®Œæˆ")
            
            return response
            
        except Exception as e:
            print(f"âŒ é—®ç­”ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "question": question,
                "agent_type": "qa"
            }
    
    def set_answer_style(self, style: str) -> bool:
        """è®¾ç½®å›žç­”é£Žæ ¼"""
        if style in self.style_prompts:
            self.answer_style = style
            self._initialized = False  # éœ€è¦é‡æ–°åˆå§‹åŒ–
            print(f"ðŸ“ å›žç­”é£Žæ ¼å·²è®¾ç½®ä¸º: {style}")
            return True
        else:
            print(f"âŒ ä¸æ”¯æŒçš„å›žç­”é£Žæ ¼: {style}")
            return False
    
    def get_available_styles(self) -> List[str]:
        """èŽ·å–å¯ç”¨çš„å›žç­”é£Žæ ¼"""
        return list(self.style_prompts.keys())
    
    def get_qa_statistics(self) -> Dict[str, Any]:
        """èŽ·å–é—®ç­”ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "agent_type": "qa",
            "status": "ready" if self._initialized else "not_initialized",
            "current_style": self.answer_style,
            "available_styles": self.get_available_styles()
        }


class EnhancedQAAgent(LawQAAgent):
    """å¢žå¼ºç‰ˆé—®ç­” Agentï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ç†è§£"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.qa_history = []
        self.context_keywords = []
    
    async def contextual_answer(self, 
                              question: str,
                              legal_context: str,
                              follow_up: bool = False) -> Dict[str, Any]:
        """
        ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é—®ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            legal_context: æ³•å¾‹æ¡æ–‡ä¸Šä¸‹æ–‡
            follow_up: æ˜¯å¦ä¸ºè¿½é—®
        
        Returns:
            é—®ç­”ç»“æžœ
        """
        # åˆ†æžé—®é¢˜ç±»åž‹
        question_type = self._analyze_question_type(question)
        
        # å¦‚æžœæ˜¯è¿½é—®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡å…³é”®è¯
        if follow_up and self.qa_history:
            last_qa = self.qa_history[-1]
            enhanced_context = f"{legal_context}\n\nã€ä¸Šä¸‹æ–‡ã€‘\nä¸Šä¸€è½®é—®é¢˜ï¼š{last_qa['question']}\nä¸Šä¸€è½®å›žç­”ï¼š{last_qa['answer'][:200]}..."
        else:
            enhanced_context = legal_context
        
        # æ‰§è¡Œé—®ç­”
        result = await self.answer(question, enhanced_context)
        
        # è®°å½•é—®ç­”åŽ†å²
        if result.get("success"):
            self.qa_history.append({
                "question": question,
                "answer": result["answer"],
                "question_type": question_type,
                "timestamp": "now",  # å¯ä»¥æ”¹ä¸ºå®žé™…æ—¶é—´æˆ³
                "follow_up": follow_up
            })
            
            # æ›´æ–°ä¸Šä¸‹æ–‡å…³é”®è¯
            self._update_context_keywords(question, result["answer"])
        
        # æ·»åŠ é—®é¢˜ç±»åž‹ä¿¡æ¯
        result["question_type"] = question_type
        result["follow_up"] = follow_up
        
        return result
    
    def _analyze_question_type(self, question: str) -> str:
        """åˆ†æžé—®é¢˜ç±»åž‹"""
        question_lower = question.lower()
        
        if any(word in question for word in ["æ€Žä¹ˆåŠž", "å¦‚ä½•", "æ€Žæ ·", "æ€Žä¹ˆåš"]):
            return "how_to"  # æ“ä½œæŒ‡å¯¼ç±»
        elif any(word in question for word in ["æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯", "å®šä¹‰", "å«ä¹‰"]):
            return "definition"  # å®šä¹‰è§£é‡Šç±»
        elif any(word in question for word in ["æ˜¯å¦", "èƒ½å¦", "å¯ä»¥", "å…è®¸", "ç¦æ­¢"]):
            return "yes_no"  # æ˜¯å¦åˆ¤æ–­ç±»
        elif any(word in question for word in ["è´£ä»»", "åŽæžœ", "å¤„ç½š", "èµ”å¿"]):
            return "consequence"  # åŽæžœè´£ä»»ç±»
        elif any(word in question for word in ["ç¨‹åº", "æµç¨‹", "æ­¥éª¤", "æ‰‹ç»­"]):
            return "procedure"  # ç¨‹åºæµç¨‹ç±»
        else:
            return "general"  # ä¸€èˆ¬å’¨è¯¢ç±»
    
    def _update_context_keywords(self, question: str, answer: str):
        """æ›´æ–°ä¸Šä¸‹æ–‡å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        legal_terms = ["æ³•å¾‹", "æ¡æ–‡", "è§„å®š", "æ³•è§„", "è´£ä»»", "ä¹‰åŠ¡", "æƒåˆ©", "åˆåŒ", "ä¾µæƒ"]
        
        question_keywords = [term for term in legal_terms if term in question]
        answer_keywords = [term for term in legal_terms if term in answer]
        
        new_keywords = list(set(question_keywords + answer_keywords))
        
        # æ›´æ–°å…³é”®è¯åˆ—è¡¨ï¼ˆä¿æŒæœ€è¿‘çš„10ä¸ªï¼‰
        self.context_keywords.extend(new_keywords)
        self.context_keywords = list(set(self.context_keywords))[-10:]
    
    def get_conversation_insights(self) -> Dict[str, Any]:
        """èŽ·å–å¯¹è¯æ´žå¯Ÿ"""
        if not self.qa_history:
            return {"message": "æš‚æ— å¯¹è¯åŽ†å²"}
        
        # ç»Ÿè®¡é—®é¢˜ç±»åž‹åˆ†å¸ƒ
        type_count = {}
        for qa in self.qa_history:
            q_type = qa.get("question_type", "unknown")
            type_count[q_type] = type_count.get(q_type, 0) + 1
        
        # ç»Ÿè®¡è¿½é—®æ¯”ä¾‹
        follow_up_count = sum(1 for qa in self.qa_history if qa.get("follow_up", False))
        follow_up_rate = follow_up_count / len(self.qa_history) if self.qa_history else 0
        
        return {
            "total_questions": len(self.qa_history),
            "question_type_distribution": type_count,
            "follow_up_rate": follow_up_rate,
            "context_keywords": self.context_keywords,
            "recent_questions": [qa["question"] for qa in self.qa_history[-3:]]
        }
    
    def reset_context(self):
        """é‡ç½®ä¸Šä¸‹æ–‡"""
        self.qa_history = []
        self.context_keywords = []
        print("ðŸ”„ é—®ç­”ä¸Šä¸‹æ–‡å·²é‡ç½®")


# åˆ›å»ºå…¨å±€é—®ç­” Agent å®žä¾‹
qa_agent = EnhancedQAAgent()


def get_qa_agent() -> EnhancedQAAgent:
    """èŽ·å–å…¨å±€é—®ç­” Agent å®žä¾‹"""
    return qa_agent


def create_qa_agent_with_style(style: str) -> EnhancedQAAgent:
    """åˆ›å»ºæŒ‡å®šé£Žæ ¼çš„é—®ç­” Agent"""
    agent = EnhancedQAAgent(answer_style=style)
    return agent 